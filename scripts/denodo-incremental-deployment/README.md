
# IncreMigrator

Automation framework for code promotion within the Denodo Major versions and also moving code from one major version to another version, leveraging Solution Manager(SM), Virtual DataPort (VDP), Scheduler, and PowerShell/Shell scripts.

Below is a high level idea on how the logic flows:
 - The process begins by identifying recently modified elements from the source environment using the Get Elements procedure, which filters records based on the last modification date.
 - A DESC VQL statement is executed on top of Get Elements query output to generate the VQL of the recently modified elements.
 - Using the VQL generated, a revision is created using Solution Manager API. This is done using a Powershell/shell script to call the API to **create revision from VQL**.
 - Once the revision is created, it is deployed to the target environment using the Solution Manager API. A JSON data source and base view are configured to trigger the deployment via API.
 - All the above steps are orchestrated sequentially with dependencies in a scheduler job.
 - Finally, we update an Audit table in any external database to keep track of the date of deployment. This audit table will be queried as a sub-query in the first step of the job to pass the required date from which the modified elements are to be fetched from the source server.


:warning: ***Note:** If you are using Denodo Platform 9, take a look at this Knowledge Base article [A Denodo CICD Pipeline example with Jenkins](https://community.denodo.com/kb/en/view/document/A%20Denodo%20CICD%20Pipeline%20example%20with%20Jenkins?category=Operation) which explains a more sophisticated flow to deploy incremental revisions automtically.*

---

## Repository Structure

```
├── vql/                             # VQL scripts to import necessary Virtual DataPort elements
├── Scheduler/                       # Scheduler exports ZIP files                      
├── Scripts/                         # PowerShell and Shell scripts for automation
├── Audit_table/                     # DDL for Audit table
└── README.md                        # Documentation & Usage Guide
```

---

## Installation Guide

### Automation Steps for Migrating within the same Denodo major version

#### 1. Virtual DataPort (Source Environment)

1. Import VQL:
   - Import the VQL available at: `vql` folder into the VDP Admin Tool or Design Studio.
   - Import the IncreMigrator_8 for Denodo v8 and IncreMigrator_9 for Denodo v9 (use the customer password **admin** while importing IncreMigrator_9)

2. Update Data Source and Base View Configurations:
    - `ds_ssh_file_executor`
        - This datasource is responsible for executing the Powershell/Shell script for creating revision from the autogenerated VQL file.
        - Edit the datasource and provide a valid hostname, port number, username and password.
        - Please make sure that the user has the required privileges to execute the script.
        - Refer [Denodo SSH Custom Wrapper - User Manual](https://community.denodo.com/docs/html/document/denodoconnects/latest/en/Denodo%20SSH%20Custom%20Wrapper%20-%20User%20Manual) documentation.
    
    - `bv_ssh_shell_script_executor`
        - The base view is created on top of `ds_ssh_file_executor` datasource to execute the Powershell/shell script
        - Open the view > Edit > Source Refresh.
        - In the Command tab, alter the file location to point to the localized script ( Download the Powershell/Shell script from the `Scripts` folder based on the Operating System where the Denodo server resides.) for windows or replace the existing command with <linux_command> for linux installations.

    - `ds_rest_api_to_deploy_revision`
        - This datasource is responsible for deploying the revision in the intended target Virtual DataPort server.
        - Open the Datasource and provide the Solution Manager configuration details in the **configure** section.(Test connecting the Data source will fail as the POST body will be included in the Base view)
        - Refer [JSON datasources](https://community.denodo.com/docs/html/accessible/8.0/vdp/vql/generating_wrappers_and_data_sources/creating_data_sources/json_sources.html#json-sources) documentation.

    - `bv_rest_api_to_deploy_revision` 
        - The base view is created on top of `ds_rest_api_to_deploy_revision` datasource to deploy revision in the target environment through Solution Manager.
        - Open the Base view > Edit > Source Refresh and replace the environmentid value "1" with the target environment ID.
        - You could get the environment id through [Solution manager REST API](https://community.denodo.com/docs/html/browse/8.0/en/solution_manager/administration/appendix/rest_api/rest_api#get-the-list-of-environments) documentation.

    - `bv_audit_table`
        - This base view is responsible for determining the StartTime. Any Virtual Database elements modified after this timestamp will be migrated.
        - This requires a JDBC table to store the datetime values from each execution of the setup, which will be used for future runs.
        - You could find the DDL for the audit_table from SQLserver. We recommend modifying it based on your database.
        - Once the table is created in any of the database, please create a Base View in vdb_incremental_deployment Virtual Database.
        - The Base View should have two fields `date_values` as timestamp datatype and `flag` as text datatype.

---

#### 2. Scheduler Administration Tool Configuration

1. Import the Scheduler components:
   - Login to Scheduler Administration Tool and import the `Scheduler export v8 - v8/scheduler_export_for_v9-v9.zip` file by navigating to Administration > import.
   - Use the custom password **admin** while importing Denodo `scheduler_export_for_v9-v9.zip` in v9 Scheduler. 

2. Update Data Sources:
   -  Navigate to Datasources and edit the following Datasources.
   - `vdp_8_source` → Point to Denodo v8 Source VDP for generating the required VQL.
   - `ds_audit_table`  → Point to the JDBC audit_table table connecting Scheduler server with the audit table.

3. Update ``job_insert_latest_entry``:
    - This job is responsible for updating the latest timestamp in the audit table.
    - In `job_insert_latest_entry` job → Exporters section → Point to audit table.
    - Refer [Exporters Section](https://community.denodo.com/docs/html/browse/8.0/en/scheduler/administration/creating_and_scheduling_jobs/configuring_new_jobs/postprocessing_section_exporters#:~:text=JDBC.%20Stores%20the%20tuples%20in%20a%20relational%20database%20table.%20To%20configure%20this%20exporter%20the%20following%20parameters%20need%20to%20be%20specified%3A) documentation.

4. This step applies only if your VDP server is configured to use a **Restricted identifier character set**:
   - Change the field names in the job `job_deploy_revision` according to the `bv_ssh_shell_script_executor` metadata.

---

#### 3. PowerShell/Shell Script Configuration

   - Modify `$Filename`/`Filename` variable in the Powershell/Shell script(Downloaded in the `1. Virtual DataPort (Source Environment)` section under `Automation Steps for Migrating within the same Denodo major version` title ) to point to the exported VQL file name from Scheduler(configured in `job_desc_vql`).
   - Replace the Host and port number of the Solution manager server in the `$Response`/`Response` variable.
   - Provide a valid username/password in the `$user,$pass`/`user,pass` variables.

---

### Automation Steps for Migrating between Denodo major versions

---
##### Please make sure that the source environment is updated to the latest version compatible with migrating the elements to a newer major version.

##### Make sure all the required properties are available in the Solution Manager server. If not, please export the properties file and import it into the Solution Manager server.
---

#### 1. Virtual DataPort (Source Environment)
   - Follow the same steps mentioned in [Automation Steps for Migrating within the same Denodo major version](#Automation Steps for Migrating within the same Denodo major version)

#### 2. Scheduler Administration Tool Configuration
   1. Import the Scheduler components:
       - Login to Scheduler Administration Tool and import the `Scheduler export v8 - v9` file by navigating to Administration > import.
       
   2. Steps 2, 3 & 4 are same as `Scheduler Administration Tool Configuration` from `Automation Steps for Migrating within the same Denodo major version`

#### 3. PowerShell/Shell Script Configuration

   - Download and localize the Powershell/Shell script from the `Scripts` folder based on the Operating System where the Denodo server resides.
   - Modify `$Filename`/`Filename` variable in the script to point to the exported VQL file from Scheduler.
   - Replace the Host and port number of the Solution manager server in the `$Response`/`Response` variable.
   - Provide a valid username/password in the `$user,$pass`/`user,pass` variables.

## Usage Guide

### Initial Setup:

1. Ensure an entry exists in the audit table .
   - This setup requires a start date to spin up.
   - We recommend performing a manual insert into the `audit table` for the initial execution. This date value will act as the starting filter to fetch the delta records.
   - The entry should be like <date_value> || 'Y' 
      - sample insert statement : **INSERT [dbo].[audit_table] ([date_values], [flag]) VALUES (CAST(N'2025-03-13T10:01:59.690' AS DateTime), N'Y')**

### Execute Jobs:

1. Run `job_insert_latest_entry` (with dependencies) to start the automation.

2. Verify Deployment:
   - Check deployment status in Solution Manager → Deployments Tab.

3. When migrating between major Denodo versions (e.g., from v8 to v9), if any new elements are introduced — such as data sources or elements containing sensitive information like usernames or passwords — we recommend exporting the properties of those elements (using the VDP Administration Tool or Design Studio) and importing them directly into the Solution Manager. This step should be performed each time a new data source or any element containing credentials is added.
---


## Points to consider for maintaining deployments between multiple targets in a single Scheduler/ Virtual DataPort server.

#### 1. audit_table

   - You will be needing individual audit tables for each deployment setup. Create a new table considering the sample DDL available in the **Audit_table** folder.
   - Create a new base view in the vdb_incremental_deployment virtual database naming the it as `bv_Audit_table_<environment_name>`.

#### 2. Powershell/Schell script
   - Create a copy of the script and name it as `create_revision_<target_environment_name>.ps1/sh`
   - Edit the `$Filname`/`Filename` variable and provide the location of the Scheduler job VQL export which you will be configuring in the next step.
   - Replace the Host and port number of the Solution manager server in the `$Response`/`Response` variable.
   - Provide a valid username/password in the `$user,$pass`/`user,pass` variables.

#### 3. Virtual DataPort Server
   - In the Virtual DataPort Administration Tool/Design Studio, edit the following elements
   1. `ds_rest_api_to_deploy_revision`
        - If you are pointing to a totally different Solution manager than the one previously defined in it, perform the following steps.
        - Create a copy of the datasource and rename it as `ds_rest_api_to_deploy_revision_<target_environment_name>` and alter the Solution Manager connectivity details by clicking on Configure tab.
        - Then create a new Base view over this datasource and provide the following post body in the **Configure** tab:

        ```
          \{
            "revisionIds":[@id],
            "environmentId": <ENVIRONMENT_ID>,
            "description": "My first deployment"
            \}

        ```
          
        
        - Replace the <ENVIRONMENT_ID> variable with the Solution manager Environment ID of the target environment.
        - Name the view as `bv_rest_api_to_deploy_revision_<target_environment_name>` and save it.
        
   2. `bv_rest_api_to_deploy_revision`
       - If you want to add a new target environment defined inside the same Solution manager server, please perform the below steps.
       - Create a copy of this view and name it as `bv_rest_api_to_deploy_revision_<target_environment_name>` and edit the target environment ID by clicking on Edit > Source refresh and save the view by providing a preexisting revision id for the changes to get reflected.
   3. `bv_ssh_shell_script_executor`
       - Create a copy of this view and name it as `bv_ssh_shell_script_executor_<target_environment_name>`
       - In the `Edit` > `Source Refresh` section, edit the command to point the **ps1/sh** file created in the previous step.


#### 4. Scheduler:
   1. In the Scheduler Administration tool, Replicate the jobs from the incremental_Deployment and rename the jobs with a suffix pointing to the target environment. After renaming the jobs should look like `job_insert_latest_entry_QA`/`job_insert_latest_entry_UAT` for all the jobs.
   2. Edit the following Scheduler Components:
        - Create a new JDBC type data source pointing to the **audit table**
        - `job_desc_vql`
            - Rename the job as `job_desc_vql_<environment_name>`
            - In the `Extraction_section` > `Query (non parameterized)`, replace the vdb_incremental_deployment with vdb_deployment.bv_audit_table_<target_environment_name>(created in the previous step).
            - In the `Exporters section`, rename the output file name as `auto_generated_vql_<target_environment_name>.vql`
        - `job_export_folders`
            - Rename the job as `job_export_folders_<environment_name>`
            -  In the `Exporters section`, rename the output file name as `auto_generated_vql_<target_environment_name>.vql`
        - `job_deploy_revision`
            - In the `Extraction section` > `Parameterized query`, replace the **bv_rest_api_to_deploy_revision** view name with the newly created **bv_rest_api_to_deploy_revision_<target_environment_name>** view.
            - In the `Extraction section` > `Query (non Parameterized)`, replace the **bv_ssh_shell_script_executor** view name with the **bv_ssh_shell_script_executor_<target_environment_name>**
        - `job_update_audit_table`
            - In the `Extraction section` > `Parameterized query`, replace the view name **bv_audit_table** with the newly created audit table base view.
        - `job_insert_latest_entry`
            - In the `Exporters section`, change the data source and other configurations pointing to the newly created audit table
        



## Points to remember:
   - Please be sure on the elements available in the source environment, because the elements which are modified after the particular timing will get migrated directly.
   
## Notes

- Tested with Denodo v8 and v9.
- Compatible with both PowerShell & Shell scripts.
- Ensure execution permissions are available for running scripts.
- User/Role privileges won't get migrated along with the elements. This feature will be included in a future release.

---

## IncreMigrator License

This project is distributed under **Apache License, Version 2.0**. 

See [LICENSE](LICENSE)

## IncreMigrator Support

This project is supported by **Denodo Community**. 

See [SUPPORT](SUPPORT.md)

## Authors

- Developed by: Dineshraja Annadurai, Muthu Rajesh Subramaniam
- Contact: dannadurai@denodo.com, msubramaniam@denodo.com
